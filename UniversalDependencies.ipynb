{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569de287-e7cd-4c06-9c75-859442428920",
   "metadata": {},
   "source": [
    "# Working with Universal Dependencies\n",
    "\n",
    "The Universal Dependencies framework distributes annotated corpora for many languages, all using the same dependency format. In this notebook, I'll demonstrate how to access such a corpus from within Python. \n",
    "\n",
    "We will work with English GUM corpus. You can find it listed under \"English\" on https://universaldependencies.org/#language- The repository with the actual corpus is at https://github.com/UniversalDependencies/UD_English-GUM/tree/master\n",
    "\n",
    "From the github repository, please download the training portion of the corpus, and put it in the same directory as this notebook. \n",
    "\n",
    "First, we will take a look at the format in which Universal Dependencies corpora are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8bcf2f5-0b05-4a70-9a96-06346284ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have conllu yet, uncomment the following\n",
    "# !python3 -m pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ae05adf-0fe1-4d76-ba45-100c4ae55bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu # reading Universal Dependency files in the CONLLu format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75cf88-7d78-4868-9b71-05a30f5bb139",
   "metadata": {},
   "source": [
    "We open the GUM corpus as a text file, and look at its first few lines. After the initial metadata, the first sentence starts with the line\n",
    "      \"# text = Aesthetic Appreciation and Spanish Art:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e103158-0fd5-4666-9713-ade344abd881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ko_kaist-ud-train.conllu\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13236d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 23010 sentences\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_conllu():\n",
    "    sentences = []\n",
    "    with open(\"ko_kaist-ud-train.conllu\", encoding='utf-8') as fh:\n",
    "        sent_lines = []\n",
    "        for raw in fh:\n",
    "            line = raw.rstrip('\\n')\n",
    "            if line.startswith('#'):\n",
    "                sent_lines.append(line)\n",
    "            elif line.strip() == '':\n",
    "                if sent_lines:\n",
    "                    sentences.append(sent_lines)\n",
    "                    sent_lines = []\n",
    "            else:\n",
    "                sent_lines.append(line)\n",
    "        if sent_lines:\n",
    "            sentences.append(sent_lines)\n",
    "\n",
    "    parsed = []\n",
    "    for s in sentences:\n",
    "        tokens = []\n",
    "        for ln in s:\n",
    "            if ln.startswith('#'):\n",
    "                continue\n",
    "            parts = ln.split('\\t')\n",
    "            if len(parts) != 10:\n",
    "                continue\n",
    "            id_, form, lemma, upos, xpos, feats, head, deprel, deps, misc = parts\n",
    "            if '-' in id_:\n",
    "                continue\n",
    "            try:\n",
    "                id_int = int(id_)\n",
    "            except Exception:\n",
    "                continue\n",
    "            token = {\n",
    "                'id': id_int,\n",
    "                'form': form,\n",
    "                'lemma': lemma,\n",
    "                'upos': upos,\n",
    "                'xpos': xpos,\n",
    "                'feats': feats,\n",
    "                'head': int(head) if head != '_' else None,\n",
    "                'deprel': deprel,\n",
    "                'deps': deps,\n",
    "                'misc': misc\n",
    "            }\n",
    "            tokens.append(token)\n",
    "        if tokens:\n",
    "            tokens.sort(key=lambda t: t['id'])\n",
    "            parsed.append(tokens)\n",
    "    return parsed\n",
    "\n",
    "sents = parse_conllu()\n",
    "print(f'Parsed {len(sents)} sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb54b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb instances (VERB tokens): 55805\n",
      "Total obj instances: 13912\n",
      "Objects immediately before verb: 10066 (72.35%)\n",
      "Objects within 1 tokens before verb: 10066 (72.35%)\n",
      "Saved distance distribution to data/project_outputs/object_verb_distance_distribution.csv\n",
      "Saved POS word count stats to data/project_outputs/pos_wordcount_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "OUT_DIR = 'data/project_outputs'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "verb_instances = 0\n",
    "obj_instances = 0\n",
    "obj_immediate = 0\n",
    "obj_within3 = 0\n",
    "dist_counter = Counter()\n",
    "\n",
    "examples = defaultdict(list) \n",
    "\n",
    "for sent_idx, tokens in enumerate(sents):\n",
    "    id_to_tok = {t['id']: t for t in tokens}\n",
    "    dependents = defaultdict(list)\n",
    "    for t in tokens:\n",
    "        if t['head'] is not None and t['head'] in id_to_tok:\n",
    "            dependents[t['head']].append(t)\n",
    "    id_to_index = {t['id']: i for i, t in enumerate(tokens)}\n",
    "\n",
    "    for i, tok in enumerate(tokens):\n",
    "        if tok['upos'] == 'VERB':\n",
    "            verb_instances += 1\n",
    "            verb_id = tok['id']\n",
    "            deps = dependents.get(verb_id, [])\n",
    "            for dep in deps:\n",
    "                if dep['deprel'] == 'obj':\n",
    "                    obj_instances += 1\n",
    "                    obj_idx = id_to_index.get(dep['id'])\n",
    "                    verb_idx = i\n",
    "                    if obj_idx is None:\n",
    "                        continue\n",
    "                    diff = verb_idx - obj_idx\n",
    "                    dist_counter[diff] += 1\n",
    "                    if diff == 1:\n",
    "                        obj_immediate += 1\n",
    "                    if 0 <= diff <= 1:\n",
    "                        obj_within3 += 1\n",
    "                    lemma = tok['lemma'] if tok['lemma'] != '_' else tok['form']\n",
    "                    if len(examples[lemma]) < 5:\n",
    "                        sent_form = ' '.join([t['form'] for t in tokens])\n",
    "                        examples[lemma].append((dep['form'], tok['form'], sent_form))\n",
    "\n",
    "if obj_instances > 0:\n",
    "    pct_immediate = obj_immediate / obj_instances * 100\n",
    "    pct_within3 = obj_within3 / obj_instances * 100\n",
    "else:\n",
    "    pct_immediate = pct_within3 = 0.0\n",
    "\n",
    "print('Verb instances (VERB tokens):', verb_instances)\n",
    "print('Total obj instances:', obj_instances)\n",
    "print(f'Objects immediately before verb: {obj_immediate} ({pct_immediate:.2f}%)')\n",
    "print(f'Objects within 1 tokens before verb: {obj_within3} ({pct_within3:.2f}%)')\n",
    "\n",
    "dist_items = sorted(dist_counter.items())\n",
    "df_dist = pd.DataFrame(dist_items, columns=['verb_minus_obj_index', 'count'])\n",
    "df_dist.to_csv(os.path.join(OUT_DIR, 'object_verb_distance_distribution.csv'), index=False)\n",
    "print('Saved distance distribution to', os.path.join(OUT_DIR, 'object_verb_distance_distribution.csv'))\n",
    "\n",
    "\n",
    "# parse words within words\n",
    "def num_words_in_word(word):\n",
    "    length = len(word.split('+'))\n",
    "    return length\n",
    "\n",
    "# analyze how many words within words by part of speech\n",
    "pos_wordcount = defaultdict(list)\n",
    "for tokens in sents:\n",
    "    for t in tokens:\n",
    "        pos = t['upos']\n",
    "        word = t['lemma']\n",
    "        count = num_words_in_word(word)\n",
    "        pos_wordcount[pos].append(count)\n",
    "import numpy as np\n",
    "pos_wordcount_stats = {}\n",
    "for pos, counts in pos_wordcount.items():\n",
    "    arr = np.array(counts)\n",
    "    pos_wordcount_stats[pos] = {\n",
    "        'mean': np.mean(arr),\n",
    "        'median': np.median(arr),\n",
    "        'max': np.max(arr),\n",
    "        'min': np.min(arr),\n",
    "        'count': len(arr)\n",
    "    }\n",
    "df_wordcount = pd.DataFrame.from_dict(pos_wordcount_stats, orient='index')\n",
    "df_wordcount.to_csv(os.path.join(OUT_DIR, 'pos_wordcount_stats.csv'))\n",
    "print('Saved POS word count stats to', os.path.join(OUT_DIR, 'pos_wordcount_stats.csv'))\n",
    "print(df_wordcount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946b07f-aa17-4b31-81db-c928176b4fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# newdoc id = GUM_academic_art\n",
      "# global.Entity = GRP-etype-infstat-salience-centering-minspan-link-identity\n",
      "# meta::author = Claire Bailey-Ross, Andrew Beresford, Daniel Smith, Claire Warwick\n",
      "# meta::dateCollected = 2017-09-13\n",
      "# meta::dateCreated = 2017-08-08\n",
      "# meta::dateModified = 2017-09-13\n",
      "# meta::genre = academic\n",
      "# meta::salientEntities = 4 (5*), 5 (5*), 44 (5*), 45 (5*), 46 (5*), 47 (5*), 27 (4*), 147 (4*), 2 (3*), 43 (3), 20 (2*), 23 (2), 63 (2), 72 (2), 73 (2), 3 (1), 19 (1), 24 (1), 26 (1), 48 (1), 49 (1), 50 (1), 62 (1), 68 (1), 69 (1), 74 (1), 76 (1), 77 (1), 78 (1), 79 (1), 158 (1)\n",
      "# meta::sourceURL = https://dh2017.adho.org/abstracts/333/333.pdf\n",
      "# meta::speakerCount = 0\n",
      "# meta::summary1 = (human) This paper presents an eye tracking study to explore how viewers experience art, focusing on a 17th Century collection of Spanish paintings by Zurbarán.\n",
      "# meta::summary2 = (claude-3-5-sonnet-20241022) This pilot study uses eye-tracking techniques to examine how viewers visually process and aesthetically experience a unique collection of 17th Century Zurbarán paintings at Auckland Castle, investigating the effects of written interpretation on art viewing behavior.\n",
      "# meta::summary3 = (gpt4o; postedited) Using eye-tracking, this study examines audience engagement with 17th Century Zurbarán paintings, providing insights into aesthetic appreciation and visual processing, exploring the influence of museum labels and implications for gallery practices, integrating Spanish art history, psychology, digital humanities, and museum studies.\n",
      "# meta::summary4 = (Llama-3.2-3B-Instruct) Researchers used eye-tracking techniques to study how people visually explore and experience 17th-century Spanish art, including the Jacob cycle by Zurbarán, and how written labels affect their behavior.\n",
      "# meta::summary5 = (Qwen2.5-7B-Instruct) A collaborative pilot project uses eye-tracking techniques to analyze how visitors visually explore and aesthetically react to a unique collection of 17th century Zurbarán paintings in order to gain insights into their viewing behaviors and potentially improve museum practices.\n",
      "# meta::title = Aesthetic Appreciation and Spanish Art: Insights from Eye-Tracking\n",
      "# newpar\n",
      "# newpar_block = head (2 s) | hi rend:::\"bold blue\" (2 s)\n",
      "# sent_id = GUM_academic_art-1\n",
      "# s_type = frag\n",
      "# s_prominence = 2\n",
      "# transition = establishment\n",
      "# text = Aesthetic Appreciation and Spanish Art:\n",
      "1\tAesthetic\taesthetic\tADJ\tJJ\tDegree=Pos\t2\tamod\t2:amod\tDiscourse=organization-heading:1->57:8:grf-ly-_-_+sem-lxchn-1,671-_+sem-lxchn-4,619-_+sem-lxchn-5,620-_|Entity=(1-abstract-new-nnnnn-cf1-2-sgl|MSeg=Aesthet-ic\n",
      "2\tAppreciation\tappreciation\tNOUN\tNN\tNumber=Sing\t0\troot\t0:root\tEntity=1)|MSeg=Appreciat-ion\n",
      "3\tand\tand\tCCONJ\tCC\t_\t5\tcc\t5:cc\t_\n",
      "4\tSpanish\tSpanish\tADJ\tJJ\tDegree=Pos\t5\tamod\t5:amod\tEntity=(2-abstract-new-snssn-cf2-2-coref|MSeg=Span-ish\n",
      "5\tArt\tart\tNOUN\tNN\tNumber=Sing\t2\tconj\t2:conj:and\tEntity=2)|SpaceAfter=No\n",
      "6\t:\t:\tPUNCT\t:\t_\t2\tpunct\t2:punct\t_\n",
      "\n",
      "# sent_id = GUM_academic_art-2\n",
      "# s_type = frag\n",
      "# s_prominence = 3\n",
      "# transition = null\n",
      "# text = Insights from Eye-Tracking\n",
      "1\tInsights\tinsight\tNOUN\tNNS\tNumber=Plur\t0\troot\t0:root\tDiscourse=elaboration-additional:2->1:0:grf-col-6-gold|Entity=(3-abstract-new-nnnns-cf1-1-coref|MSeg=In-sigh-t-s\n",
      "2\tfrom\tfrom\tADP\tIN\t_\t5\tcase\t5:case\t_\n",
      "3\tEye\teye\tNOUN\tNN\tNumber=Sing\t5\tcompound\t5:compound\tEntity=(4-abstract-new-sssss-cf2-3-coref(5-object-new-sssss-cf3-1-coref)|SpaceAfter=No|XML=<w>\n",
      "4\t-\t-\tPUNCT\tHYPH\t_\t3\tpunct\t3:punct\tSpaceAfter=No\n",
      "5\tTracking\ttracking\tNOUN\tNN\tNumber=Sing\t1\tnmod\t1:nmod:from\tEntity=4)3)|MSeg=Track-ing|XML=</w>\n",
      "\n",
      "# newpar\n",
      "# newpar_block = p (1 s)\n",
      "# sent_id = GUM_academic_art-3\n",
      "# s_type = frag\n",
      "# s_prominence = 2\n",
      "# transition = null\n",
      "# text = Claire Bailey-Ross claire.bailey-ross@port.ac.uk University of Portsmouth, United Kingdom\n",
      "1\tClaire\tClaire\tPROPN\tNNP\tNumber=Sing\t0\troot\t0:root\tDiscourse=attribution-positive:3->57:7:sem-atsrc-12-46-_+syn-rpr-676-_|Entity=(6-person-new-nnnnn-cf1-1,2,4-coref\n",
      "2\tBailey\tBailey\tPROPN\tNNP\tNu\n"
     ]
    }
   ],
   "source": [
    "print(data[:4000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc952160-39df-4b1f-9527-54240f9da389",
   "metadata": {},
   "source": [
    "As you can see, this is a tabular format. There is a line for each word in the sentence, and the information for that word is given in tab-delimited cells, for example:\n",
    "\n",
    "```2\tAppreciation\tappreciation\tNOUN\tNN\tNumber=Sing\t0\troot\t0:root\tEntity=1)|MSeg=Appreciat-ion```\n",
    "\n",
    "This is the CoNLL-U format, which originated with a shared task at the Conference on Natural Language Learning (CoNLL). \n",
    "\n",
    "There is a Python package, conllu, that is made for reading CoNLL-U data. Once we have read the GUM corpus into a string, we can parse it with conllu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f2e94-c22a-4fca-9442-ff4620567801",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = conllu.parse(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45e066-23f5-4fdf-827e-b65ff1a5adaf",
   "metadata": {},
   "source": [
    "The content of `sentences` is a sequence of TokenList objects. Here is the one for the 10th sentence of the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2333cc-4aba-4d54-ae98-76a3fc1b57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenList<Thus, ,, the, time, it, takes, and, the, ways, of, visually, exploring, an, artwork, can, inform, about, its, relevance, ,, interestingness, ,, and, even, its, aesthetic, appeal, ., metadata={sent_id: \"GUM_academic_art-11\", s_type: \"sub\", s_prominence: \"3\", transition: \"establishment\", text: \"Thus, the time it takes and the ways of visually exploring an artwork can inform about its relevance, interestingness, and even its aesthetic appeal.\"}>\n"
     ]
    }
   ],
   "source": [
    "print(sentences[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836027d-685d-4613-b4b1-89ae92254c4a",
   "metadata": {},
   "source": [
    "We can access the entries on the TokenList through a for-loop, or using an index. Here is the first token of sentence 10. As you can see, it is a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba93605-0b32-4f1f-b35f-34d2421814cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'form': 'Thus',\n",
       " 'lemma': 'thus',\n",
       " 'upos': 'ADV',\n",
       " 'xpos': 'RB',\n",
       " 'feats': None,\n",
       " 'head': 16,\n",
       " 'deprel': 'advmod',\n",
       " 'deps': [('advmod', 16)],\n",
       " 'misc': {'Discourse': 'context-background:12->23:7:_',\n",
       "  'PDTB': 'Explicit:Contingency.Cause.Result:thus:107:79-106:108-134',\n",
       "  'SpaceAfter': 'No'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence10 = sentences[10]\n",
    "firstword = sentence10[0]\n",
    "firstword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591f3d7-7f12-47eb-b7e0-ae2dadf1b4cc",
   "metadata": {},
   "source": [
    "You can access the entries in that dictionary by their keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd8ff8-ca4e-4f16-9231-865453e85431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thus'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstword[\"lemma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c2bfd8-91dd-4a60-a737-ca819e741975",
   "metadata": {},
   "source": [
    "To better understand this big dictionary, it helps to view it as an attribute-value matrix. Here is the first word of the 10th sentence of the UD_English-GUM corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fba85e-117a-40bc-b2ba-1f09995b47b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstword = {'id': 1,\n",
    "  'form': 'Thus',\n",
    "  'lemma': 'thus',\n",
    "  'upos': 'ADV',\n",
    "  'xpos': 'RB',\n",
    "  'feats': None,\n",
    "  'head': 16,\n",
    "  'deprel': 'advmod',\n",
    "  'deps': None,\n",
    "  'misc': {'SpaceAfter': 'No'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98da69-4ce7-4805-8bb1-f69609ba10a7",
   "metadata": {},
   "source": [
    "This is the following attribute-value matrix (AVM):\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ll}\n",
    "\\text{id:} & 1\\\\\n",
    "\\text{form:} & 'Thus'\\\\\n",
    "\\text{lemma:} & 'thus'\\\\\n",
    "\\text{upos:} &  'ADV'\\\\\n",
    "\\text{xpos:} & 'RB'\\\\\n",
    "\\text{feats:} &  None\\\\\n",
    "\\text{head:} & 16\\\\\n",
    "\\text{deprel:}  & advmod\\\\\n",
    "\\text{deps:}  & None\\\\\n",
    "\\text{misc:} & \\left[\\begin{array}{ll}\n",
    "\\text{SpaceAfter:} & 'No'\n",
    "\\end{array}\\right]\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "As you saw above, you can access an entry in this attribute-value matrix through its dictionary key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e51ee5-055c-4d1c-8176-751bab20de51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thus'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstword[\"lemma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f84425-20f4-4249-a478-5c258ffc9a6a",
   "metadata": {},
   "source": [
    "One of the values in the AVM is itself an AVM. To access the value that tells you whether there is a space after the word, you need to specify the whole path of keys. `firstword[\"misc\"]` accesses a dictionary, namely `{'SpaceAfter': 'No'}`, which again has keys, in particular `SpaceAfter`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4578946-d0d3-49ef-90e0-50f0f092919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstword[\"misc\"][\"SpaceAfter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0425615d-45b3-45fb-aa3f-48af620c03d1",
   "metadata": {},
   "source": [
    "The Universal Dependencies representation of a whole sentence is a list of tokens, that is, a list of dictionaries (=AVMs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de31cd0-1665-4d18-b683-d3448fe71b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence10 = [{'id': 1,\n",
    "  'form': 'Thus',\n",
    "  'lemma': 'thus',\n",
    "  'upos': 'ADV',\n",
    "  'xpos': 'RB',\n",
    "  'feats': None,\n",
    "  'head': 16,\n",
    "  'deprel': 'advmod',\n",
    "  'deps': None,\n",
    "  'misc': {'SpaceAfter': 'No'}},\n",
    " {'id': 2,\n",
    "  'form': ',',\n",
    "  'lemma': ',',\n",
    "  'upos': 'PUNCT',\n",
    "  'xpos': ',',\n",
    "  'feats': None,\n",
    "  'head': 1,\n",
    "  'deprel': 'punct',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 3,\n",
    "  'form': 'the',\n",
    "  'lemma': 'the',\n",
    "  'upos': 'DET',\n",
    "  'xpos': 'DT',\n",
    "  'feats': {'Definite': 'Def', 'PronType': 'Art'},\n",
    "  'head': 4,\n",
    "  'deprel': 'det',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 4,\n",
    "  'form': 'time',\n",
    "  'lemma': 'time',\n",
    "  'upos': 'NOUN',\n",
    "  'xpos': 'NN',\n",
    "  'feats': {'Number': 'Sing'},\n",
    "  'head': 16,\n",
    "  'deprel': 'nsubj',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 5,\n",
    "  'form': 'it',\n",
    "  'lemma': 'it',\n",
    "  'upos': 'PRON',\n",
    "  'xpos': 'PRP',\n",
    "  'feats': {'Case': 'Nom',\n",
    "   'Gender': 'Neut',\n",
    "   'Number': 'Sing',\n",
    "   'Person': '3',\n",
    "   'PronType': 'Prs'},\n",
    "  'head': 6,\n",
    "  'deprel': 'nsubj',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 6,\n",
    "  'form': 'takes',\n",
    "  'lemma': 'take',\n",
    "  'upos': 'VERB',\n",
    "  'xpos': 'VBZ',\n",
    "  'feats': {'Mood': 'Ind',\n",
    "   'Number': 'Sing',\n",
    "   'Person': '3',\n",
    "   'Tense': 'Pres',\n",
    "   'VerbForm': 'Fin'},\n",
    "  'head': 4,\n",
    "  'deprel': 'acl:relcl',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 7,\n",
    "  'form': 'and',\n",
    "  'lemma': 'and',\n",
    "  'upos': 'CCONJ',\n",
    "  'xpos': 'CC',\n",
    "  'feats': None,\n",
    "  'head': 9,\n",
    "  'deprel': 'cc',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 8,\n",
    "  'form': 'the',\n",
    "  'lemma': 'the',\n",
    "  'upos': 'DET',\n",
    "  'xpos': 'DT',\n",
    "  'feats': {'Definite': 'Def', 'PronType': 'Art'},\n",
    "  'head': 9,\n",
    "  'deprel': 'det',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 9,\n",
    "  'form': 'ways',\n",
    "  'lemma': 'way',\n",
    "  'upos': 'NOUN',\n",
    "  'xpos': 'NNS',\n",
    "  'feats': {'Number': 'Plur'},\n",
    "  'head': 4,\n",
    "  'deprel': 'conj',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 10,\n",
    "  'form': 'of',\n",
    "  'lemma': 'of',\n",
    "  'upos': 'SCONJ',\n",
    "  'xpos': 'IN',\n",
    "  'feats': None,\n",
    "  'head': 12,\n",
    "  'deprel': 'mark',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 11,\n",
    "  'form': 'visually',\n",
    "  'lemma': 'visually',\n",
    "  'upos': 'ADV',\n",
    "  'xpos': 'RB',\n",
    "  'feats': None,\n",
    "  'head': 12,\n",
    "  'deprel': 'advmod',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 12,\n",
    "  'form': 'exploring',\n",
    "  'lemma': 'explore',\n",
    "  'upos': 'VERB',\n",
    "  'xpos': 'VBG',\n",
    "  'feats': {'VerbForm': 'Ger'},\n",
    "  'head': 9,\n",
    "  'deprel': 'acl',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 13,\n",
    "  'form': 'an',\n",
    "  'lemma': 'a',\n",
    "  'upos': 'DET',\n",
    "  'xpos': 'DT',\n",
    "  'feats': {'Definite': 'Ind', 'PronType': 'Art'},\n",
    "  'head': 14,\n",
    "  'deprel': 'det',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 14,\n",
    "  'form': 'artwork',\n",
    "  'lemma': 'artwork',\n",
    "  'upos': 'NOUN',\n",
    "  'xpos': 'NN',\n",
    "  'feats': {'Number': 'Sing'},\n",
    "  'head': 12,\n",
    "  'deprel': 'obj',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 15,\n",
    "  'form': 'can',\n",
    "  'lemma': 'can',\n",
    "  'upos': 'AUX',\n",
    "  'xpos': 'MD',\n",
    "  'feats': {'VerbForm': 'Fin'},\n",
    "  'head': 16,\n",
    "  'deprel': 'aux',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 16,\n",
    "  'form': 'inform',\n",
    "  'lemma': 'inform',\n",
    "  'upos': 'VERB',\n",
    "  'xpos': 'VB',\n",
    "  'feats': {'VerbForm': 'Inf'},\n",
    "  'head': 0,\n",
    "  'deprel': 'root',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 17,\n",
    "  'form': 'about',\n",
    "  'lemma': 'about',\n",
    "  'upos': 'ADP',\n",
    "  'xpos': 'IN',\n",
    "  'feats': None,\n",
    "  'head': 19,\n",
    "  'deprel': 'case',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 18,\n",
    "  'form': 'its',\n",
    "  'lemma': 'its',\n",
    "  'upos': 'PRON',\n",
    "  'xpos': 'PRP$',\n",
    "  'feats': {'Gender': 'Neut',\n",
    "   'Number': 'Sing',\n",
    "   'Person': '3',\n",
    "   'Poss': 'Yes',\n",
    "   'PronType': 'Prs'},\n",
    "  'head': 19,\n",
    "  'deprel': 'nmod:poss',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 19,\n",
    "  'form': 'relevance',\n",
    "  'lemma': 'relevance',\n",
    "  'upos': 'NOUN',\n",
    "  'xpos': 'NN',\n",
    "  'feats': {'Number': 'Sing'},\n",
    "  'head': 16,\n",
    "  'deprel': 'obl',\n",
    "  'deps': None,\n",
    "  'misc': {'SpaceAfter': 'No'}},\n",
    " {'id': 20,\n",
    "  'form': ',',\n",
    "  'lemma': ',',\n",
    "  'upos': 'PUNCT',\n",
    "  'xpos': ',',\n",
    "  'feats': None,\n",
    "  'head': 21,\n",
    "  'deprel': 'punct',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 21,\n",
    "  'form': 'interestingness',\n",
    "  'lemma': 'interestingness',\n",
    "  'upos': 'NOUN',\n",
    "  'xpos': 'NN',\n",
    "  'feats': {'Number': 'Sing'},\n",
    "  'head': 19,\n",
    "  'deprel': 'conj',\n",
    "  'deps': None,\n",
    "  'misc': {'SpaceAfter': 'No'}},\n",
    " {'id': 22,\n",
    "  'form': ',',\n",
    "  'lemma': ',',\n",
    "  'upos': 'PUNCT',\n",
    "  'xpos': ',',\n",
    "  'feats': None,\n",
    "  'head': 27,\n",
    "  'deprel': 'punct',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 23,\n",
    "  'form': 'and',\n",
    "  'lemma': 'and',\n",
    "  'upos': 'CCONJ',\n",
    "  'xpos': 'CC',\n",
    "  'feats': None,\n",
    "  'head': 27,\n",
    "  'deprel': 'cc',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 24,\n",
    "  'form': 'even',\n",
    "  'lemma': 'even',\n",
    "  'upos': 'ADV',\n",
    "  'xpos': 'RB',\n",
    "  'feats': None,\n",
    "  'head': 27,\n",
    "  'deprel': 'advmod',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 25,\n",
    "  'form': 'its',\n",
    "  'lemma': 'its',\n",
    "  'upos': 'PRON',\n",
    "  'xpos': 'PRP$',\n",
    "  'feats': {'Gender': 'Neut',\n",
    "   'Number': 'Sing',\n",
    "   'Person': '3',\n",
    "   'Poss': 'Yes',\n",
    "   'PronType': 'Prs'},\n",
    "  'head': 27,\n",
    "  'deprel': 'nmod:poss',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 26,\n",
    "  'form': 'aesthetic',\n",
    "  'lemma': 'aesthetic',\n",
    "  'upos': 'ADJ',\n",
    "  'xpos': 'JJ',\n",
    "  'feats': {'Degree': 'Pos'},\n",
    "  'head': 27,\n",
    "  'deprel': 'amod',\n",
    "  'deps': None,\n",
    "  'misc': None},\n",
    " {'id': 27,\n",
    "  'form': 'appeal',\n",
    "  'lemma': 'appeal',\n",
    "  'upos': 'NOUN',\n",
    "  'xpos': 'NN',\n",
    "  'feats': {'Number': 'Sing'},\n",
    "  'head': 19,\n",
    "  'deprel': 'conj',\n",
    "  'deps': None,\n",
    "  'misc': {'SpaceAfter': 'No'}},\n",
    " {'id': 28,\n",
    "  'form': '.',\n",
    "  'lemma': '.',\n",
    "  'upos': 'PUNCT',\n",
    "  'xpos': '.',\n",
    "  'feats': None,\n",
    "  'head': 16,\n",
    "  'deprel': 'punct',\n",
    "  'deps': None,\n",
    "  'misc': None}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492bac8-0a69-41a0-adb1-2ef59ec67350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Thus ADV 16 advmod\n",
      "2 , PUNCT 1 punct\n",
      "3 the DET 4 det\n",
      "4 time NOUN 16 nsubj\n",
      "5 it PRON 6 nsubj\n",
      "6 takes VERB 4 acl:relcl\n",
      "7 and CCONJ 9 cc\n",
      "8 the DET 9 det\n",
      "9 ways NOUN 4 conj\n",
      "10 of SCONJ 12 mark\n",
      "11 visually ADV 12 advmod\n",
      "12 exploring VERB 9 acl\n",
      "13 an DET 14 det\n",
      "14 artwork NOUN 12 obj\n",
      "15 can AUX 16 aux\n",
      "16 inform VERB 0 root\n",
      "17 about ADP 19 case\n",
      "18 its PRON 19 nmod:poss\n",
      "19 relevance NOUN 16 obl\n",
      "20 , PUNCT 21 punct\n",
      "21 interestingness NOUN 19 conj\n",
      "22 , PUNCT 27 punct\n",
      "23 and CCONJ 27 cc\n",
      "24 even ADV 27 advmod\n",
      "25 its PRON 27 nmod:poss\n",
      "26 aesthetic ADJ 27 amod\n",
      "27 appeal NOUN 19 conj\n",
      "28 . PUNCT 16 punct\n"
     ]
    }
   ],
   "source": [
    "# now we can iterate through the AVMs for this sentence, and \n",
    "# print informati0n for each one\n",
    "for token in sentence10:\n",
    "    print(token[\"id\"], token[\"form\"], token[\"upos\"], \n",
    "          token[\"head\"], token[\"deprel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb7c79-8b4e-43e5-a09b-5e2baede941a",
   "metadata": {},
   "source": [
    "Now say we want to determine how often we have subject-verb-object (SVO) versus SOV versus VSO etc. in a Universal Dependencies corpus. To do that, we would like to have an AVM for a word that includes all its dependents. For the verb \"inform\" in the sentence above, we would like the AVM to list that \"time\" (word 4) is the nsubj of \"inform\", and \"relevance\" (word 19) is its obl:\n",
    "\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{ll}\n",
    "\\text{form:} & inform\\\\\n",
    "\\text{id:} & 16\\\\\n",
    "\\text{upos:} & VERB\\\\\n",
    "\\text{dep:} & \\[ \\left[\\begin{array}{ll}\n",
    "\\text{id:} & 4\\\\\n",
    "\\text{deprel:} & nsubj\\end{array}\\right], \n",
    "\\left[\\begin{array}{ll}\n",
    "\\text{id:} & 19\\\\\n",
    "\\text{deprel:} & obl\\end{array}\\right]\\]\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "As a Python data structure, this AVM is rather complex: It is a dictionary, but under the key \"dep\" the value is a list of dictionaries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811f49f-7ff4-4b54-9589-3b026a6fe6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inform_avm_with_deps = { \"form\" : \"inform\",\n",
    "                        \"id\" : 16,\n",
    "                        \"upos\" : \"VERB\",\n",
    "                        \"dep\" : [ {\"id\" : 4, \"deprel\" : \"nsubj\"}, \n",
    "                                  {\"id\" : 19, \"deprel\" : \"obl\"}]\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b79e50-3d38-4a8f-8e11-76f89e33d83c",
   "metadata": {},
   "source": [
    "Here is how we make a version of sentence 10 that has such an AVM for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e8456-009c-4331-a75c-2dc41bf90d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Thus',\n",
       "  'id': 1,\n",
       "  'upos': 'ADV',\n",
       "  'dep': [{'id': 2, 'deprel': 'punct'}]},\n",
       " {'form': ',', 'id': 2, 'upos': 'PUNCT', 'dep': []},\n",
       " {'form': 'the', 'id': 3, 'upos': 'DET', 'dep': []},\n",
       " {'form': 'time',\n",
       "  'id': 4,\n",
       "  'upos': 'NOUN',\n",
       "  'dep': [{'id': 3, 'deprel': 'det'},\n",
       "   {'id': 6, 'deprel': 'acl:relcl'},\n",
       "   {'id': 9, 'deprel': 'conj'}]},\n",
       " {'form': 'it', 'id': 5, 'upos': 'PRON', 'dep': []},\n",
       " {'form': 'takes',\n",
       "  'id': 6,\n",
       "  'upos': 'VERB',\n",
       "  'dep': [{'id': 5, 'deprel': 'nsubj'}]},\n",
       " {'form': 'and', 'id': 7, 'upos': 'CCONJ', 'dep': []},\n",
       " {'form': 'the', 'id': 8, 'upos': 'DET', 'dep': []},\n",
       " {'form': 'ways',\n",
       "  'id': 9,\n",
       "  'upos': 'NOUN',\n",
       "  'dep': [{'id': 7, 'deprel': 'cc'},\n",
       "   {'id': 8, 'deprel': 'det'},\n",
       "   {'id': 12, 'deprel': 'acl'}]},\n",
       " {'form': 'of', 'id': 10, 'upos': 'SCONJ', 'dep': []},\n",
       " {'form': 'visually', 'id': 11, 'upos': 'ADV', 'dep': []},\n",
       " {'form': 'exploring',\n",
       "  'id': 12,\n",
       "  'upos': 'VERB',\n",
       "  'dep': [{'id': 10, 'deprel': 'mark'},\n",
       "   {'id': 11, 'deprel': 'advmod'},\n",
       "   {'id': 14, 'deprel': 'obj'}]},\n",
       " {'form': 'an', 'id': 13, 'upos': 'DET', 'dep': []},\n",
       " {'form': 'artwork',\n",
       "  'id': 14,\n",
       "  'upos': 'NOUN',\n",
       "  'dep': [{'id': 13, 'deprel': 'det'}]},\n",
       " {'form': 'can', 'id': 15, 'upos': 'AUX', 'dep': []},\n",
       " {'form': 'inform',\n",
       "  'id': 16,\n",
       "  'upos': 'VERB',\n",
       "  'dep': [{'id': 1, 'deprel': 'advmod'},\n",
       "   {'id': 4, 'deprel': 'nsubj'},\n",
       "   {'id': 15, 'deprel': 'aux'},\n",
       "   {'id': 19, 'deprel': 'obl'},\n",
       "   {'id': 28, 'deprel': 'punct'}]},\n",
       " {'form': 'about', 'id': 17, 'upos': 'ADP', 'dep': []},\n",
       " {'form': 'its', 'id': 18, 'upos': 'PRON', 'dep': []},\n",
       " {'form': 'relevance',\n",
       "  'id': 19,\n",
       "  'upos': 'NOUN',\n",
       "  'dep': [{'id': 17, 'deprel': 'case'},\n",
       "   {'id': 18, 'deprel': 'nmod:poss'},\n",
       "   {'id': 21, 'deprel': 'conj'},\n",
       "   {'id': 27, 'deprel': 'conj'}]},\n",
       " {'form': ',', 'id': 20, 'upos': 'PUNCT', 'dep': []},\n",
       " {'form': 'interestingness',\n",
       "  'id': 21,\n",
       "  'upos': 'NOUN',\n",
       "  'dep': [{'id': 20, 'deprel': 'punct'}]},\n",
       " {'form': ',', 'id': 22, 'upos': 'PUNCT', 'dep': []},\n",
       " {'form': 'and', 'id': 23, 'upos': 'CCONJ', 'dep': []},\n",
       " {'form': 'even', 'id': 24, 'upos': 'ADV', 'dep': []},\n",
       " {'form': 'its', 'id': 25, 'upos': 'PRON', 'dep': []},\n",
       " {'form': 'aesthetic', 'id': 26, 'upos': 'ADJ', 'dep': []},\n",
       " {'form': 'appeal',\n",
       "  'id': 27,\n",
       "  'upos': 'NOUN',\n",
       "  'dep': [{'id': 22, 'deprel': 'punct'},\n",
       "   {'id': 23, 'deprel': 'cc'},\n",
       "   {'id': 24, 'deprel': 'advmod'},\n",
       "   {'id': 25, 'deprel': 'nmod:poss'},\n",
       "   {'id': 26, 'deprel': 'amod'}]},\n",
       " {'form': '.',\n",
       "  'id': 28,\n",
       "  'upos': 'PUNCT',\n",
       "  'dep': [{'id': 16, 'deprel': 'root'}]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reformat_sentence(sentence):\n",
    "    # first we initialize each AVM to have an empty dependencies list\n",
    "    sentence_reformatted = [ ]\n",
    "    for token in sentence:\n",
    "        sentence_reformatted.append( { \"form\" : token[\"form\"], \n",
    "                                    \"id\" : token[\"id\"],\n",
    "                                    \"upos\" : token[\"upos\"],\n",
    "                                    \"dep\" : [ ]\n",
    "                                  } )\n",
    "\n",
    "    # now we add dependencies\n",
    "    for token in sentence:\n",
    "        # looking up the head of this token. index is that head minus one.\n",
    "        myhead_ix = token[\"head\"] - 1\n",
    "        # print(token[\"form\"], token[\"id\"], token[\"head\"], sentence10_reformat[myhead_ix][\"form\"])\n",
    "        # adding this token to the head's dependencies\n",
    "        sentence_reformatted[ myhead_ix ][\"dep\"].append({ \"id\" : token[\"id\"],\n",
    "                                                       \"deprel\" : token[\"deprel\"]})\n",
    "\n",
    "    return sentence_reformatted\n",
    "    \n",
    "reformat_sentence(sentence10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07568beb-0ea6-45aa-872b-9edcf2122ae1",
   "metadata": {},
   "source": [
    "Based on this data structure, we can determine whether the subject is before the verb: If so, its ID is lower than that of the verb. We can also determine whether the subject is before the object: If so, its ID is lower than that of the the object.\n",
    "\n",
    "We can also see how far away from the verb the subject is, by computing the difference between the IDs of the verb and its subject. In the same way, we can determine how far away from the verb the direct object is. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
